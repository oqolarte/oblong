---
title: "Antifragile"
date: 2024-09-03
draft: false
math: false
---

*Mostly raw notes from Nassim Nicholas Taleb's book of the same title.
Each paragraph can be considered a self-contained note.*

Learning things and building to a level of resilience requires practice.
Action trumps thinking alone. **Practice over theory**. On the flip
side, words are scalable, and through them we can share knowledge across
generations and spanning large distances.

**Black swan**, as coined by Taleb, is a rare event with significant
impacts. It is impossible to calculate the risks of such events and
predict when (not if) they would happen.

**Test of asymmetry**: "Anything that has more upside than downside from
random events (or certain shocks) is antifragile; the reverse if
fragile."

[Social revolution](/revolution) that changes everything and everyone
from the ground up might be slow to progress, but under the "right
amount" of [disorder](/chaos),
it will make all things affected antifragile,
except the empire---the [empire](/empire) will fall.

If most of history comprise
black swans, how useful is it to create routines? Shouldn't we all start
vibrating in random directions until we toughen up?

Ethics of risk-taking: One shall not have antifragility at the expense
of the fragility of others.

In the modern iteration of *progress*, what are we sacrificing, or
giving away, or destroying in its name? If progress would require a
rainforest be razed flat to make way for farmlands or data centers,
then have we really progressed? If so, on whose metrics?

[Fragilistas](https://fs.blog/the-fragilista/), naive rationalists
according to Taleb, are usually white-collar knowledge workers who
believe that things they do not understand do not exist---a dangerous,
arrogant thought that makes them vulnerable to harm. The author adds,
"The fragilista ... is one who makes you engage in policies and actions,
all artificial, in which the benefits are small and visible, and the
side effects potentially severe and invisible."

It is okay to have one's actions result to small benefits, especially if
it is sustainable in terms of effort. But think about the possible
negative side effects: are they going to be so severe that they outweigh
the benefits? Some example/s:
- taking medication with little benefits but would greatly damage kidneys and/or liver;
- doing *everything* and effectively accomplishes nothing;

Ignorance is a key human trait we could harness and be proud of to deal
with life's uncertainty. It *is* okay to not know everything.

To have integrity, one must eat one's own cooking. Software developers
even call this
[dogfooding](https://en.wikipedia.org/wiki/Eating_your_own_dog_food),
that is, the practice of using one own's services, or in lay terms,
believing *and* doing what one says and/or endorses. But Taleb goes a
bit further when he puts his ideas on antifragility and black swans:
"Compromising is condoning." This is a bold statement which I don't
necessarily agree with. In a world that is largely gray areas and middle
grounds, [building better relationships](/friendship) with people often
means meeting them halfway. Of course, there are many instances where we
cannot compromise, like we certainly don't want to enable harm-doers.

[Stochastic tinkering](https://cleanlanguage.com/stochastic-tinkering/) is
discovering something new that you don't intend
to, and using it anyway to carry on with the search/experiment.

The fragility of large systems (e.g., big corporations) which many
people have come to rely on for daily tasks puts its dependents as
[potential] collateral damage when these systems eventually break. Still
using big corpos as our example, how many times have they tanked and put
the lives of people in harm? [Recall the 2008 global financial crisis](https://en.wikipedia.org/wiki/2007%E2%80%932008_financial_crisis).

As societies continue to evolve, we continue to be more vulnerable each
time we choose the benefits of cutting-edge [technology](/technology).
Many people could not live if many of their comforts, larely granted
and/or made possible by these techs, are taken away.

*Hormesis*---a word coined by pharmacologists---is ingesting small dose
of harm, and is believed to have beneficial effects, make humans
stronger, more robust. Examples:
- fasting (harming the body via hunger);
- physical exercise (harming the body by stressing the body);
- vaccination (harming the body by injecting diseases)
- freedom (harming the status quo and comforts by being involved in
  small conflicts)

In psychology, [post-traumatic growth](https://www.psychologytoday.com/us/basics/post-traumatic-growth) (PTG)
is positive psychological change experienced as a result of struggling
with highly challenging, highly stressful life circumstances. Survivors
of trauma forge stronger relationships with loved ones and with other
victims. It is
commonly reported in cancer survivors. A more controversial example
would be sexual assault victims "taking back" their sexuality by
processing their trauma to eventually re-enjoy having [lots of] sex,
sometimes becoming hypersexual.

Related to PTG, Taleb recommends to get into "serious" trouble to force
ourselves to innovate. I guess it's up to us how serious is *serious*.

When we delagate the boring tasks to automation, we are getting back
some of the time that would otherwise be spent in dread. But are we also
saving ourselves from future mishaps which *may* lead to PTG? Perhaps,
we should *not* delegate 100% of the boring tasks.
[Autonomation](/autonomation) is the right balance, and it allows us to
combine human intelligence with the efficiency of automated machine
work.

In meetings, both formal and informal, I seem to be unknowingly
"disfluent," which is a fancy way of saying that, for some reason,
obvious or otherwise, people cannot immediately understand what I am
saying. (Side note: given my fascination for things [absurd](/absurdism)
and [surreal](/surrealism), my occassional disfluency may not be out of
brand at all.) But Taleb, and some pro-disfluency psychology
researchers, believe that disfluency forces the audience assuming they
haven't zoned out yet, to actively listen more and digest what the
speaker is trying to say. This forces the brain to engage more with the
activity, and thus retaining more of the important information.

Planning with redundancy in mind is a step closer to being more
antifragile. Extra preparedness is never wasteful because something
unusual always happens. Some questions to consider:
- How extra-prepared are you willing to be?
- Do you have the necessary resources to achieve the level of
  extra-preparedness you want? If not, is a lower tier possible?

In a hypothetical tight-knit [community](/community) where things are
shared among its neightbors, having multiple, say, power tools of the
same kind makes the tool library robust. If one circular saw breaks, the
community's work will not be jeopardized.

Unhealthy behaviors can cause antifragile emotions that might be a form
of abuse. Let's be wary that stressors like these do exist as net harm;
and that antifragility also exists in negative forms.

Non-living things cannot be intrinsically antifragile. But if/when they
can be [repurposed and/or upcycled](/repair), then this human
intervention introduces strength and life, and one could argue that this
things are made robust again.

Now, as living beings, to aspire for equilibrium, for "peace", is to
want Death, because it is *the* end state that is truly peaceful.
Nothing happens after one dies. So, we must learn to accept and learn to
thrive in places where there are stressors that could make us stronger.

My "unwanted" feelings *are* source of vital information. Mood including
sadness and anxiety could be a good source of intelligence as they
[in]directly notify me of what is happening in my surroundings and the
people in it.

Longer life spans means more time. More time means more exposure to
stressors. Optimistically, this could also mean more chances to affect
change.

Being human ulitimately is to live a colorful life far from convenience
and efficiency that empire has set up to blind us with and bind us to
its comforts, so we couldn't, wouldn't think of anything else. Being
human is not being a tourist in this world. We explore, because that is
more fulfilling. Chaos nurtures.

No one and nothing can prepare for the future, let alone withstand *all*
of its random obstacles. Even with modern tech, we cannot perfectly
predict (i.e., 100% accuracy) the future. Robust and antifragile systems
don't rely on predictions, unlike fragile ones, whose predictions need
to be as accurate as possible. In my honest opinion, though,
[futurist prediction is only fun to read *sometimes*](https://danluu.com/futurist-predictions/); I'd rather read
science fiction.

How small can an error be for it to be exploited for the benefit of the
entire system? Must lives be lost? Taleb explains that "small" means
[statistically small](/statistics/#statistical-significance).

If we don't look after the individuals that are local to us, are we also
allowing cracks in the society as whole?

In the book, Taleb argues that "we humans may have to be self-centered
at the expense of other species, at the risk of ecological fragility, if
it insures our survival." Not sure if I fully grasp what he's saying,
but humans **must** work with nature because we are a part of it. Our
interests should NOT prevail over but along WITH those of the Nature.

Taleb has hinted on the benefits of [abolishing](/abolition)
nation-states and building bottom-up communities. But he still latches
on to "city-states" which, if I understand correctly, is still operated
by State, albeit a much smaller version of it.

Small is beautiful. The aggregate of many small things culminate to
diverse insights, which is always a good thing.

Fat tails are highly unpredictable events that play a disproportionate
role which are far more volatile in the long run.

Taleb discusses the *Great Turkey Problem*: Turkeys are fed to get fat
in time for Thanksgiving. Turkey thinks that butchers love turkeys, a
projection based on past data. However, fat tails can't be predicted by
historical data. In this scenario, the fat tail (AKA the great turkey
problem) is the time when the butcher will slaughter the turkey to
become food, which the bird most likely did not foresee, until it's too
late.

Modernity is a human-made domination of the natural environment, the
systematic smoothening of world's jaggedness in order for it to be more
comfortable to "walk on" especially for the few people who can afford
it. Taleb adds, "Sophistication continuously puts us ahead of ourselves,
creating things we are [less] capable of understanding." This is kind of
like how ethics can't keep up with the evolution of tech or the
advancement of pharmaceuticals.

Taleb posits that [iatrogenics](/iatrogenics), or naive interventions to
heal or repair, incur risks to those directly affected by the
intervention (e.g., patients of the doctor). In medicine, this
intervention *harms* the patient in the long run, even if in the short
term it seems otherwise.

There is no reward for bringing the truth except in maybe bringing the
collective consciousness one step closer to it. Even then, recognition
might be sparse and/or not within lifetime.

[Access to more data](/data-management) increases exposure to more
noise, unless there is a reliable way to turn data to insights, or
better, wisdom---minus the profit incentive, of course.

In making new or updating current systems which we live in, we should
include during the [design](/design) phase ways to withstand or get
stronger once entropy inevitably increases.

Seneca's barbell illustrates the idea of dealing with two extremes and
avoiding the middle. One extreme is playing it safe in some areas; the
other is taking lots of small risks to be more robust.

In the intersection of barbell and [communication](/communication),
Taleb suggests that we should consume *both* trashy gossip magazines and
classic sophisticated works. "Trashy" gossip also is a treasure trove of
info, if one digs deep enough; it can reveal the current desires of the
masses.

Freedom is the ultimate option. In the current empire, it might mean
having [financial independence](/personal-finance/#financial-independence)--- to have enough fuck-you money to not be obligated to exchange my life to "earn a living." Beyond that, freedom means being with the family I choose, and the community I want to be part of.

[Fringe ideas and ideologies](/politics) grounded in the daily life are
antifragile because they are capable to be widely adopted yet no one
central authority is enforcing people to adopt these.

It is okay to not be smart. Being smart is overrated. Better: don't do
unintelligent things, especially those that might cause harm to you or
others.

Options = asymmetry + rationality  
where rationality is assessing what good to keep and what bad to ditch.

Trial and error, while not efficient, is still an effective way of
searching for answer/solution to a problem. In cases where the reward is
a positive Black Swan, every dead end is itself a useful information,
because it narrows down the search for the reward. Some call it
investment.

Optionality allows for progress. Narratives can be used to distort it.
The former allows us to learn from mistakes; the latter can hinder us
by invoking irreversible effects.
