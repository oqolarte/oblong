---
title: "Artificial intelligence"
date: 2023-01-23
draft: false
---

AI refers to computer programs that can craft systems to perform tasks
requiring human-like intellect, like discovery, inference, and
reasoning. A subset of AI is [Machine Learning](/ml) (ML).

{{< toc >}}

## Key Domains of AI:

- Natural Language Processing: Understanding and generating human language.
- Computer Vision: Making sense of visual data.
- Text to Speech: Converting written text into spoken words.
- Motion/Robotics: Making machines move or perform tasks.
- Generative AI: Systems that can create content.
- *many more*

It's something that computer scientists and [engineers](/engineering)
are developing to supposedly automate boring tasks so we can focus on
making art, but doing quite the opposite.

LLMs are *language* models (it even says so in the name) and have not
been specifically been trained to solve mathematical problems.

## Generative AI

One specific type of AI, and perhaps the most popular, is generative AI
(gen AI), which is AI that can generate new content, like text, images,
or other media from a prompt, which is just a set of specific
instructions, that the user supplies.

One might use gen AI for any of the following:
- Create content
- Analyze information quickly
- Summarize information to use in research
- Simplify day-to-day work

## Cons of AI

[Make no mistake---AI is owned by Big Tech](https://www.technologyreview.com/2023/12/05/1084393/make-no-mistake-ai-is-owned-by-big-tech/).
A lot of AI-related startups and research labs depend on the
infrastructure that Microsoft, Amazon, and Google provides.

So far, the true costs of gen AI has been obscured by insane amounts of
venture capital. When the bill comes due, these AI tools will either
become prohibitively expensive or they will turn to
[advertising](/no-ads) and/or propaganda. Like all current big tech
companies, the product is not the software but its users; and the true
customers are the venture capitalists who are paying for it all.

Can we even achieve [full automation without the human touch](/autonomation)?
In CNET's YouTube video "[Apple Intelligence is for the Stupid Ones](https://www.youtube.com/watch?v=D0V554NyXWM)",
Bridget Carey observes that the point of AI "was supposed to save us
time[.]" Carey further asks:

> But with AI, what is the chore that we're trying to solve for? Is
> communication the chore? Is reading comprehension and critical
> thinking the chore? [...] So, is the value having the computer do the
> thinking for us?

### Slop as result of offloading creativity to AI

I believe that the "chore" was menial and dirty jobs that machines could
do better and quicker while also freeing up humans of time.

If, on the other hand, the chore is creativity, then I don't want AI
"solving" that "problem", especially if the consequence is ingesting
works of art and blending them all into bland slop for lazy
creative-wannabes.

Most gen AIs are trained on copyrighted material, and in the process
actively harm the people they stole from by pushing them out of creative
fields, making those fields even more difficult to enter for working
class people.

### Privacy and security nightmare

When AI systems become agents on behalf of the user, doing things with
some degree of autonomy, it will be *more* of a [privacy](/privacy) and
[security](/security) nightmare.

As it currently stands, they already are for women and children’s
safety, especially with apps that "nudify" photos.

AI might be recording users’ data without their knowledge or
[consent](/consent) which is a major privacy concern. People are now talking
to ChatGPT as though it were a empathetic human friend. At Post-human
Posting, the author FAFOs about this on his funny write up
"[I Built an AI Girlfriend And It Ruined My Life](https://posthuman.blog/i-made-an-ai-gf/)".

All of the intimate details that one shares with an LLM will go to a
corporation that does not care about people unless it's about their data
from which they could extract more profit.

### AI reinforces stereotypes

In Victoria Turk's piece on
[how AI reduces the world to stereotypes](https://restofworld.org/2023/ai-image-stereotypes/),
the author quoted Amba Kak, executive director of AI Now
Institute:

> Essentially what this is doing is flattening descriptions of, say, ‘an
> Indian person’ or ‘a Nigerian house’ into particular stereotypes [old
> man with a beard, and a run-down house, respectively] which
> could be viewed in a negative light.

AI worsens misinformation and low-quality content because it lacks the
ethical nuance with which to include in the contents it produces.

### Environmental costs of AI

In [an interview by *The Guardian*](https://www.theguardian.com/technology/2021/jun/06/microsofts-kate-crawford-ai-is-neither-artificial-nor-intelligent),
Kate Crawford said something on what people should know about how AI products are
made (emphasis and added hyperlink mine):

> We aren’t used to thinking about these systems in terms of the
> environmental costs. But saying, “Hey, Alexa, order me some toilet
> rolls,” invokes into being this chain of extraction, which goes all
> around the planet… We’ve got a long way to go before this is green
> technology. Also, systems might seem automated but when we pull away
> the curtain we see large amounts of low paid labour, everything from
> crowd work categorising data to the [never-ending toil](/anti-work) of
> shuffling Amazon boxes. **AI is neither artificial nor intelligent. It
> is made from natural resources and it is people who are performing the
> tasks to make the systems appear autonomous.**

### Proliferation of misinformation

Gen AIs normalize the spread of lies and misinformation. If our
educators failed to teach the importance of critical thinking and the
act of fact checking in the Age of (Mis)Information, then AI will be
used to accelerate [fascism](/fascism) in many parts of the world.

### Grief tech

Another one: "grief tech" lays out the plot for the next Black Mirror
episode. Except that creators of the show *already* produced a similar
one, in the episode "[Be Right Back](https://en.wikipedia.org/wiki/Be_Right_Back)." Grief tech fails to
realize that death is final and that it is natural to grieve loves lost.
On the other hand, what if grief tech is used for cases of [enforced disappearances](/216) AND make the training data and source code free and open source?
For more info on grief tech, check these articles:
- [From AI avatars of loved ones who have died to conversations with the deceased via a chatbot—can tech create a form of life after death?](https://www.vml.com/insight/grief-tech)
- [The race to optimize grief](https://www.vox.com/culture/23965584/grief-tech-ghostbots-ai-startups-replika-ethics)
- [Grief Tech Uses AI to Give You (and Your Loved Ones) Digital Immortality](https://singularityhub.com/2023/08/16/grief-tech-uses-ai-to-give-you-and-your-loved-ones-digital-immortality/)

## What to think of LLM

LLM is Large Language Model (LLM), the most well-known
gateway to which is ChatGPT; AGI is Artificial General Intelligence, the
notion of a computer that can think like people can.

![Unmasking of AI](/image/statistical-ai.jpeg)

LLMs are not meant to be used as search engines.
LLMs are, in simpler terms, based on [statistics](/statistics) in that
they only predict a likely answer. To understand it better, when you
type a question or prompt, you're actually asking the LLM to give back
the most likely response of people to that sort of query/prompt. Don't
expect it give a "right answer."

## AI under [capitalism](/capitalism)

All tech can never not be political, and that includes---and
especially---AI.

At least the closed-source, proprietary versions out there, AI allows
the tech oligopoly to access skill while removing from the skilled the
ability to access wealth.

## Further reading

- [Comprehensive Guide to Safe and Privacy-Respecting AI Usage](https://github.com/iAnonymous3000/ai-privacy-guide) -- "This
  guide aims to help users of all backgrounds understand and use AI
  technologies in a safe and [privacy-respecting manner](/privacy)."
- [Hype, Sustainability, and the Price of the Bigger-is-Better Paradigm in AI](https://arxiv.org/pdf/2409.14160) (pdf) -- A paper on how "smaller AI models often perform better" and "obsession with bigness has severe collateral consequences" ([Whittaker](https://mastodon.world/@Mer__edith/113197090927589168), 2024)
- [AI Cleanup/catchphrases compilation in Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:WikiProject_AI_Cleanup/AI_catchphrases)
- [Short toot from Alex Ștefănescu](https://chaos.social/@catileptic/114879931445497328) about "brainstorming with ChatGPT"
