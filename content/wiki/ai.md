---
title: "On Artificial Intelligence"
date: 2023-01-23
draft: false
---

AI crafts systems that can perform tasks requiring human-like intellect,
like discovery, inference, and reasoning. A subset of AI is
[Machine Learning](/ml) (ML).

Key Domains of AI:

- Natural Language Processing: Understanding and generating human language.
- Computer Vision: Making sense of visual data.
- Text to Speech: Converting written text into spoken words.
- Motion/Robotics: Making machines move or perform tasks.
- Generative AI: Systems that can create content.
- *many more*

More clarification: LLM is Large Language Model, the most well-known
gateway to which is ChatGPT; AGI is Artificial General Intelligence, the
notion of a computer that can think like people can.

It's something that computer scientists and [engineers](/engineering)
are developing to supposedly automate boring tasks so we can focus on
making art, but doing quite the opposite.

[Make no mistake---AI is owned by Big Tech](https://www.technologyreview.com/2023/12/05/1084393/make-no-mistake-ai-is-owned-by-big-tech/).
A lot of AI-related startups and research labs depend on the
infrastructure that Microsoft, Amazon, and Google provides.

[Can we even achieve full automation without the human touch](/autonomation)?

I don't want that, after having read Victoria Turk's piece on
[how AI reduces the world to stereotypes](https://restofworld.org/2023/ai-image-stereotypes/).
In it, the author quoted Amba Kak, executive director of AI Now
Institute:

> Essentially what this is doing is flattening descriptions of, say, ‘an
> Indian person’ or ‘a Nigerian house’ into particular stereotypes [old
> man with a beard, and a run-down house, respectively] which
> could be viewed in a negative light.

AI worsens misinformation and low-quality content because it lacks the
ethical nuance with which to include in the contents it produces.
