---
title: "On Artificial Intelligence"
date: 2023-01-23
draft: false
---

AI crafts systems that can perform tasks requiring human-like intellect,
like discovery, inference, and reasoning. A subset of AI is
[Machine Learning](/ml) (ML).

Key Domains of AI:

- Natural Language Processing: Understanding and generating human language.
- Computer Vision: Making sense of visual data.
- Text to Speech: Converting written text into spoken words.
- Motion/Robotics: Making machines move or perform tasks.
- Generative AI: Systems that can create content.
- *many more*

More clarification: LLM is Large Language Model, the most well-known
gateway to which is ChatGPT; AGI is Artificial General Intelligence, the
notion of a computer that can think like people can.

It's something that computer scientists and [engineers](/engineering)
are developing to supposedly automate boring tasks so we can focus on
making art, but doing quite the opposite.

## Cons of AI

[Make no mistake---AI is owned by Big Tech](https://www.technologyreview.com/2023/12/05/1084393/make-no-mistake-ai-is-owned-by-big-tech/).
A lot of AI-related startups and research labs depend on the
infrastructure that Microsoft, Amazon, and Google provides.

[Can we even achieve full automation without the human touch](/autonomation)?

I don't want that, after having read Victoria Turk's piece on
[how AI reduces the world to stereotypes](https://restofworld.org/2023/ai-image-stereotypes/).
In it, the author quoted Amba Kak, executive director of AI Now
Institute:

> Essentially what this is doing is flattening descriptions of, say, ‘an
> Indian person’ or ‘a Nigerian house’ into particular stereotypes [old
> man with a beard, and a run-down house, respectively] which
> could be viewed in a negative light.

AI worsens misinformation and low-quality content because it lacks the
ethical nuance with which to include in the contents it produces.

In [an interview by *The Guardian*](https://www.theguardian.com/technology/2021/jun/06/microsofts-kate-crawford-ai-is-neither-artificial-nor-intelligent), Kate Crawford said on what people should know about how AI products are made (emphasis mine):

> We aren’t used to thinking about these systems in terms of the
> environmental costs. But saying, “Hey, Alexa, order me some toilet
> rolls,” invokes into being this chain of extraction, which goes all
> around the planet… We’ve got a long way to go before this is green
> technology. Also, systems might seem automated but when we pull away
> the curtain we see large amounts of low paid labour, everything from
> crowd work categorising data to the [never-ending toil](/anti-work) of
> shuffling Amazon boxes. **AI is neither artificial nor intelligent. It
> is made from natural resources and it is people who are performing the
> tasks to make the systems appear autonomous.**

## What to think of LLM

Large language models (LLMs) are not meant to be used as search engines.
LLMs are, in simpler terms, based on [statistics](/statistics) in that
they only predict a likely answer. To understand it better, when you
type a question or prompt, you're actually asking the LLM to give back
the most likely response of people to that sort of query/prompt. Don't
expect it give a "right answer."
